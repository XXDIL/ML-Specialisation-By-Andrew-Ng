## Improving Deep Neural Networks - Andrew Ng
Link to the Coursera Page : [Coursera](https://www.coursera.org/learn/deep-neural-network)

This is the second part of a 5 part series, this course will dive deeper into the following topics
* Hyperparameter tuning
* Regularization
* Optimization.

### [Week 1](https://github.com/XXDIL/ML-Specialisation-By-Andrew-Ng/tree/master/ML-Specialization/Improving%20Deep%20Neural%20Networks/Week1)
* **Lesson Topic:** 
  * Train-Dev-Test sets
  * Bias and Variance
  * Regularization
  * Dropout
  * Other Regularization Methods
  * Normalizing Inputs
  * Vanishing and Exploding Gradients
  * Weight Initialization
  * Gradient Checking and Implementation
* **Quiz:** 
  * Practical aspects of deep learning
* **Assignment:** 
  * Initialization
  * Regularization
  * Gradient Checking
### [Week 2](https://github.com/XXDIL/ML-Specialisation-By-Andrew-Ng/tree/master/ML-Specialization/Improving%20Deep%20Neural%20Networks/Week2)
* **Lesson Topic:** 
  * Mini-batch Gradient Descent
  * Exponentially Weighted Averages
  * Bias Correction
  * Gradient Descent with Momentum
  * RMSprop
  * Adam Optimization
  * Learning Rate Decay
  * Problem of Local Optima
* **Quiz:** 
  * Optimization Algorithms
* **Assignment:** 
  * Optimization
### [Week 3](https://github.com/XXDIL/ML-Specialisation-By-Andrew-Ng/tree/master/ML-Specialization/Improving%20Deep%20Neural%20Networks/Week3)
* **Lesson Topic:** 
  * Tuning Process
  * Hyperparameters Tuning
  * Normalizing activations
  * Fitting Batch Norm
  * Softmax Regression
  * DL Frameworks
  * TensorFlow
* **Quiz:** 
  * Hyperparameter tuning
  * Batch Normalization
  * Programming Frameworks
* **Assignment:** 
  * TensorFlow
